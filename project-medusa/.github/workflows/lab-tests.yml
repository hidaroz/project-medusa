name: Lab Environment Tests

on:
    push:
        branches: [main, develop]
        paths:
            - "lab-environment/**"
            - "medusa-cli/**"
            - ".github/workflows/lab-tests.yml"
    pull_request:
        branches: [main, develop]
    workflow_dispatch:
    schedule:
        # Run daily at 2 AM UTC
        - cron: '0 2 * * *'

jobs:
    # ========================================================================
    # Lab Environment Validation
    # ========================================================================
    lab-validation:
        name: Validate Lab Environment
        runs-on: ubuntu-latest
        timeout-minutes: 20

        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Set up Docker Buildx
              uses: docker/setup-buildx-action@v3

            - name: Start lab environment
              working-directory: ./lab-environment
              run: |
                  echo "ğŸš€ Starting MEDUSA lab environment..."
                  docker-compose up -d --build
                  echo "â³ Waiting for services to start..."
                  sleep 30

            - name: Verify lab services
              working-directory: ./lab-environment
              run: |
                  echo "ğŸ” Verifying lab services..."
                  chmod +x verify.sh
                  ./verify.sh --verbose || true

            - name: Check container status
              run: |
                  echo "ğŸ“Š Container Status:"
                  docker ps -a
                  echo ""
                  echo "ğŸ“‹ Container Logs (last 50 lines):"
                  docker-compose -f lab-environment/docker-compose.yml logs --tail=50

            - name: Run comprehensive verification
              working-directory: ./lab-environment
              run: |
                  # Give services more time if needed
                  sleep 15
                  ./verify.sh --json > verification-results.json || true
                  cat verification-results.json

            - name: Upload verification results
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: lab-verification-results
                  path: lab-environment/verification-results.json

            - name: Cleanup lab environment
              if: always()
              working-directory: ./lab-environment
              run: |
                  docker-compose down -v

    # ========================================================================
    # Integration Tests Against Lab
    # ========================================================================
    integration-tests:
        name: Integration Tests (Lab)
        runs-on: ubuntu-latest
        timeout-minutes: 30
        needs: lab-validation

        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Set up Python
              uses: actions/setup-python@v5
              with:
                  python-version: "3.11"
                  cache: "pip"

            - name: Install system dependencies
              run: |
                  sudo apt-get update
                  sudo apt-get install -y nmap netcat-openbsd

            - name: Install Python dependencies
              working-directory: ./medusa-cli
              run: |
                  python -m pip install --upgrade pip
                  pip install -e .
                  pip install pytest pytest-asyncio pytest-cov pytest-timeout
                  pip install requests psutil

            - name: Start lab environment
              working-directory: ./lab-environment
              run: |
                  docker-compose up -d
                  sleep 30

            - name: Run integration tests
              working-directory: ./medusa-cli
              run: |
                  pytest tests/integration/ \
                    -v \
                    --tb=short \
                    --cov=medusa \
                    --cov-report=xml \
                    --cov-report=term-missing \
                    -m "integration and requires_docker" \
                    --junitxml=test-results-integration.xml
              env:
                  PYTHONPATH: ${{ github.workspace }}/medusa-cli/src

            - name: Upload integration test results
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: integration-test-results
                  path: |
                      medusa-cli/test-results-integration.xml
                      medusa-cli/coverage.xml

            - name: Cleanup
              if: always()
              working-directory: ./lab-environment
              run: docker-compose down -v

    # ========================================================================
    # End-to-End Tests
    # ========================================================================
    e2e-tests:
        name: E2E Tests (Autonomous Mode)
        runs-on: ubuntu-latest
        timeout-minutes: 30
        needs: integration-tests

        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Set up Python
              uses: actions/setup-python@v5
              with:
                  python-version: "3.11"

            - name: Install dependencies
              working-directory: ./medusa-cli
              run: |
                  python -m pip install --upgrade pip
                  pip install -e .
                  pip install pytest pytest-asyncio pytest-timeout
                  pip install requests nmap

            - name: Install system tools
              run: |
                  sudo apt-get update
                  sudo apt-get install -y nmap netcat-openbsd curl

            - name: Start lab environment
              working-directory: ./lab-environment
              run: |
                  docker-compose up -d
                  sleep 45

            - name: Verify lab is ready
              working-directory: ./lab-environment
              run: |
                  chmod +x verify.sh
                  ./verify.sh --verbose

            - name: Run E2E tests (mock LLM)
              working-directory: ./medusa-cli
              run: |
                  pytest tests/e2e/ \
                    -v \
                    --tb=short \
                    -m "e2e and not requires_api" \
                    --timeout=300 \
                    --junitxml=test-results-e2e.xml
              env:
                  PYTHONPATH: ${{ github.workspace }}/medusa-cli/src

            - name: Run E2E tests (real LLM)
              if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
              working-directory: ./medusa-cli
              run: |
                  pytest tests/e2e/ \
                    -v \
                    --tb=short \
                    -m "e2e and requires_api" \
                    --timeout=600 \
                    --junitxml=test-results-e2e-real.xml
              env:
                  GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
                  PYTHONPATH: ${{ github.workspace }}/medusa-cli/src
              continue-on-error: true

            - name: Upload E2E test results
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: e2e-test-results
                  path: medusa-cli/test-results-e2e*.xml

            - name: Cleanup
              if: always()
              working-directory: ./lab-environment
              run: docker-compose down -v

    # ========================================================================
    # Performance Tests
    # ========================================================================
    performance-tests:
        name: Performance & Benchmarks
        runs-on: ubuntu-latest
        timeout-minutes: 20

        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Set up Python
              uses: actions/setup-python@v5
              with:
                  python-version: "3.11"

            - name: Install dependencies
              working-directory: ./medusa-cli
              run: |
                  python -m pip install --upgrade pip
                  pip install -e .
                  pip install pytest pytest-asyncio pytest-benchmark psutil

            - name: Run performance tests
              working-directory: ./medusa-cli
              run: |
                  pytest tests/performance/ \
                    -v \
                    --tb=short \
                    -m "performance" \
                    --junitxml=test-results-performance.xml
              env:
                  PYTHONPATH: ${{ github.workspace }}/medusa-cli/src

            - name: Upload performance results
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: performance-test-results
                  path: medusa-cli/test-results-performance.xml

    # ========================================================================
    # Security Tests
    # ========================================================================
    security-tests:
        name: Security & Input Validation
        runs-on: ubuntu-latest
        timeout-minutes: 15

        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Set up Python
              uses: actions/setup-python@v5
              with:
                  python-version: "3.11"

            - name: Install dependencies
              working-directory: ./medusa-cli
              run: |
                  python -m pip install --upgrade pip
                  pip install -e .
                  pip install pytest pytest-asyncio

            - name: Run security tests
              working-directory: ./medusa-cli
              run: |
                  pytest tests/security/ \
                    -v \
                    --tb=short \
                    -m "security" \
                    --junitxml=test-results-security.xml
              env:
                  PYTHONPATH: ${{ github.workspace }}/medusa-cli/src

            - name: Upload security test results
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: security-test-results
                  path: medusa-cli/test-results-security.xml

    # ========================================================================
    # Test Summary
    # ========================================================================
    test-summary:
        name: Lab Tests Summary
        runs-on: ubuntu-latest
        needs: [lab-validation, integration-tests, e2e-tests, performance-tests, security-tests]
        if: always()

        steps:
            - name: Download all artifacts
              uses: actions/download-artifact@v4

            - name: Display test results
              run: |
                  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
                  echo "â•‘         MEDUSA Lab Environment Test Summary              â•‘"
                  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                  echo ""
                  echo "Job Results:"
                  echo "  Lab Validation:      ${{ needs.lab-validation.result }}"
                  echo "  Integration Tests:   ${{ needs.integration-tests.result }}"
                  echo "  E2E Tests:           ${{ needs.e2e-tests.result }}"
                  echo "  Performance Tests:   ${{ needs.performance-tests.result }}"
                  echo "  Security Tests:      ${{ needs.security-tests.result }}"
                  echo ""

            - name: Check if critical tests passed
              run: |
                  if [[ "${{ needs.lab-validation.result }}" != "success" ]]; then
                    echo "âŒ Lab validation failed"
                    exit 1
                  fi
                  if [[ "${{ needs.integration-tests.result }}" != "success" ]]; then
                    echo "âŒ Integration tests failed"
                    exit 1
                  fi
                  if [[ "${{ needs.e2e-tests.result }}" != "success" ]]; then
                    echo "âŒ E2E tests failed"
                    exit 1
                  fi
                  echo "âœ… All critical tests passed!"
