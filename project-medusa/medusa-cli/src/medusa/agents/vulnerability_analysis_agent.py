"""
Vulnerability Analysis Agent
Specializes in vulnerability assessment and CVE correlation
"""

from typing import Dict, Any, List
import json

from .base_agent import BaseAgent, AgentCapability
from .data_models import AgentTask, AgentResult, AgentStatus


class VulnerabilityAnalysisAgent(BaseAgent):
    """
    Vulnerability Analysis Agent

    Responsibilities:
    - Analyze reconnaissance findings for vulnerabilities
    - Match services/versions to known CVEs
    - Assess vulnerability severity and exploitability
    - Recommend exploitation strategies
    """

    def __init__(self, *args, **kwargs):
        """Initialize Vulnerability Analysis Agent"""
        super().__init__(
            name="VulnAnalysisAgent",
            capabilities=[AgentCapability.VULNERABILITY_ANALYSIS],
            *args,
            **kwargs
        )

    async def execute_task(self, task: AgentTask) -> AgentResult:
        """
        Execute vulnerability analysis task

        Task types:
        - analyze_findings: Analyze findings for vulnerabilities
        - match_cves: Match services to CVE database
        - assess_exploitability: Assess if vulnerabilities are exploitable

        Args:
            task: Vulnerability analysis task

        Returns:
            AgentResult with vulnerability assessment
        """
        self.logger.info(f"Executing vulnerability analysis task: {task.task_type}")

        if task.task_type == "analyze_findings":
            return await self._analyze_findings(task)
        elif task.task_type == "match_cves":
            return await self._match_cves(task)
        elif task.task_type == "assess_exploitability":
            return await self._assess_exploitability(task)
        else:
            return AgentResult(
                task_id=task.task_id,
                agent_name=self.name,
                status=AgentStatus.FAILED,
                error=f"Unknown task type: {task.task_type}"
            )

    async def _analyze_findings(self, task: AgentTask) -> AgentResult:
        """
        Analyze findings for potential vulnerabilities

        Uses context fusion to:
        - Search CVE database for relevant vulnerabilities
        - Get exploitation techniques from MITRE
        - Access historical vulnerability data
        """
        findings = task.parameters.get("findings", [])
        target = task.parameters.get("target")

        # Build context with CVE search
        context = {}
        if self.context_engine:
            try:
                context = self.context_engine.build_context_for_vulnerability_analysis(
                    findings=findings,
                    target=target
                )
            except Exception as e:
                self.logger.warning(f"Failed to build context: {e}")

        # Build prompt
        prompt = self._build_analysis_prompt(findings, context)

        # Use LLM with routing (MODERATE complexity)
        llm_response = await self.llm_client.generate_with_routing(
            prompt=prompt,
            task_type="analyze_vulnerabilities",
            force_json=True
        )

        # Parse response
        try:
            analysis = json.loads(llm_response.content)
        except json.JSONDecodeError:
            import re
            json_match = re.search(r'\{.*\}', llm_response.content, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group(0))
            else:
                analysis = {"vulnerabilities": []}

        # Extract vulnerabilities as findings
        vulnerabilities = analysis.get("vulnerabilities", [])

        result = AgentResult(
            task_id=task.task_id,
            agent_name=self.name,
            status=AgentStatus.COMPLETED,
            findings=vulnerabilities,
            recommendations=analysis.get("exploitation_recommendations", []),
            metadata={
                "target": target,
                "total_findings_analyzed": len(findings),
                "vulnerabilities_found": len(vulnerabilities),
                "cves_referenced": len(context.get("relevant_cves", [])),
                "high_severity_count": len([v for v in vulnerabilities if v.get("severity") == "high"])
            },
            tokens_used=llm_response.tokens_used,
            cost_usd=llm_response.metadata.get("cost_usd", 0.0)
        )

        return result

    async def _match_cves(self, task: AgentTask) -> AgentResult:
        """
        Match services/software to CVE database

        Uses vector store to find relevant CVEs
        """
        services = task.parameters.get("services", [])

        matched_cves = []

        # Search CVE database for each service
        if self.context_engine and self.context_engine.vector_store:
            for service in services:
                try:
                    service_name = service.get("name", service.get("service", "unknown"))
                    version = service.get("version", "")

                    query = f"{service_name} {version} vulnerability" if version else f"{service_name} vulnerability"

                    cves = self.context_engine.vector_store.search_cves(
                        query=query,
                        n_results=3
                    )

                    for cve in cves:
                        matched_cves.append({
                            "service": service_name,
                            "version": version,
                            "cve_id": cve["cve_id"],
                            "severity": cve["severity"],
                            "cvss": cve["cvss"],
                            "description": cve["description"][:200],  # Truncate
                            "relevance_score": cve["relevance_score"]
                        })
                except Exception as e:
                    self.logger.warning(f"Failed to search CVEs for {service}: {e}")

        # Use LLM to analyze CVE matches
        prompt = f"""Analyze these CVE matches and assess which are most relevant:

Services Detected:
{json.dumps(services, indent=2)}

CVE Matches:
{json.dumps(matched_cves, indent=2)}

Provide assessment in JSON format:
{{
    "priority_vulnerabilities": [
        {{
            "cve_id": "CVE-XXXX-XXXX",
            "service": "service name",
            "severity": "critical|high|medium|low",
            "exploitability": "high|medium|low",
            "reasoning": "why this is important",
            "recommended_action": "what to do next"
        }}
    ]
}}"""

        llm_response = await self.llm_client.generate_with_routing(
            prompt=prompt,
            task_type="analyze_cve_matches",
            force_json=True
        )

        try:
            assessment = json.loads(llm_response.content)
        except json.JSONDecodeError:
            import re
            json_match = re.search(r'\{.*\}', llm_response.content, re.DOTALL)
            if json_match:
                assessment = json.loads(json_match.group(0))
            else:
                assessment = {"priority_vulnerabilities": matched_cves}

        result = AgentResult(
            task_id=task.task_id,
            agent_name=self.name,
            status=AgentStatus.COMPLETED,
            findings=assessment.get("priority_vulnerabilities", []),
            metadata={
                "total_cves_matched": len(matched_cves),
                "services_analyzed": len(services)
            },
            tokens_used=llm_response.tokens_used,
            cost_usd=llm_response.metadata.get("cost_usd", 0.0)
        )

        return result

    async def _assess_exploitability(self, task: AgentTask) -> AgentResult:
        """Assess whether vulnerabilities are exploitable"""
        vulnerabilities = task.parameters.get("vulnerabilities", [])

        prompt = f"""Assess the exploitability of these vulnerabilities:

Vulnerabilities:
{json.dumps(vulnerabilities, indent=2)}

For each vulnerability, assess:
1. Exploitability (high/medium/low)
2. Required access level
3. Complexity of exploitation
4. Potential impact
5. Available exploits/tools

Provide assessment in JSON format:
{{
    "assessments": [
        {{
            "vulnerability": "description",
            "cve_id": "CVE-XXXX-XXXX",
            "exploitability": "high|medium|low",
            "access_required": "remote|local|adjacent",
            "complexity": "low|medium|high",
            "impact": "description",
            "available_exploits": ["tool1", "tool2"],
            "exploitation_steps": ["step1", "step2"],
            "recommended_tools": ["tool1", "tool2"]
        }}
    ],
    "overall_risk": "critical|high|medium|low"
}}"""

        llm_response = await self.llm_client.generate_with_routing(
            prompt=prompt,
            task_type="assess_exploitability",
            force_json=True
        )

        try:
            assessment = json.loads(llm_response.content)
        except json.JSONDecodeError:
            import re
            json_match = re.search(r'\{.*\}', llm_response.content, re.DOTALL)
            if json_match:
                assessment = json.loads(json_match.group(0))
            else:
                assessment = {"assessments": []}

        result = AgentResult(
            task_id=task.task_id,
            agent_name=self.name,
            status=AgentStatus.COMPLETED,
            findings=assessment.get("assessments", []),
            metadata={
                "overall_risk": assessment.get("overall_risk", "unknown"),
                "vulnerabilities_assessed": len(vulnerabilities)
            },
            tokens_used=llm_response.tokens_used,
            cost_usd=llm_response.metadata.get("cost_usd", 0.0)
        )

        return result

    def _build_analysis_prompt(
        self,
        findings: List[Dict[str, Any]],
        context: Dict[str, Any]
    ) -> str:
        """Build comprehensive vulnerability analysis prompt"""
        prompt = f"""You are a vulnerability analysis expert. Analyze these findings for security vulnerabilities:

Findings:
{json.dumps(findings, indent=2)}

"""

        # Add CVE context if available
        if context.get("relevant_cves"):
            prompt += "\nRelevant CVEs from database:\n"
            for cve in context["relevant_cves"][:5]:
                prompt += f"- {cve['cve_id']}: {cve['severity']} - {cve['description'][:100]}...\n"

        # Add exploitation techniques
        if context.get("exploitation_techniques"):
            prompt += "\nRelevant Exploitation Techniques:\n"
            for tech in context["exploitation_techniques"][:3]:
                prompt += f"- {tech['technique_id']}: {tech['technique_name']}\n"

        prompt += """

Provide analysis in JSON format:
{
    "vulnerabilities": [
        {
            "finding_id": "related finding",
            "vulnerability_type": "type",
            "severity": "critical|high|medium|low",
            "cvss_score": 0.0,
            "cve_references": ["CVE-XXXX-XXXX"],
            "affected_component": "component name",
            "description": "detailed description",
            "impact": "potential impact",
            "exploitability": "high|medium|low"
        }
    ],
    "exploitation_recommendations": [
        {
            "vulnerability": "which vuln",
            "approach": "exploitation approach",
            "tools": ["tool1", "tool2"],
            "difficulty": "easy|medium|hard",
            "mitre_technique": "T1234"
        }
    ],
    "risk_summary": {
        "overall_risk": "critical|high|medium|low",
        "critical_count": 0,
        "high_count": 0,
        "exploitable_count": 0
    }
}"""

        return prompt
